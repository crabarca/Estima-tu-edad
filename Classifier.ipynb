{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20960\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.externals import joblib\n",
    "import scipy.io as sio\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "featureMat= 'pca200_sfs100.mat'\n",
    "\n",
    "features = sio.loadmat('selected/{}'.format(featureMat) )\n",
    "x_train = features['trainFeatures']\n",
    "y_train = [item[0] for item in features['trainLabels']]\n",
    "\n",
    "x_test = features['testFeatures']\n",
    "y_test = [item[0] for item in features['testLabels']]\n",
    "\n",
    "def img_per_class(directory):\n",
    "    ageRangeCounter = {1: 0, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0}\n",
    "    for filename in os.listdir(directory):\n",
    "    # To count images per group when renamed\n",
    "        group = int(filename.split(\"_\")[1])\n",
    "        ageRangeCounter[group] += 1\n",
    "    \n",
    "    totalSum = sum([v for k,v in ageRangeCounter.items()])\n",
    "    print(\"Total sum: \", totalSum)\n",
    "    print(\"Per class: \", ageRangeCounter)\n",
    "    \n",
    "    return ageRangeCounter\n",
    "\n",
    "# ageRangeCounter = img_per_class('datasets/train_folder')\n",
    "n_samples = 1500\n",
    "do_sampling = False\n",
    "def sampling(x_train, n_samples, class_counter):\n",
    "    x_buff = []\n",
    "    imgCounter = class_counter\n",
    "    # returns 7 classes with n_samples per class\n",
    "    index = 0\n",
    "    for i in range(1, 8):\n",
    "        if i == 1:\n",
    "            chunk = x_train[:1500]\n",
    "#             print(len(chunk))\n",
    "            x_buff = chunk\n",
    "        else:\n",
    "            chunk = x_train[index:index+n_samples]\n",
    "            x_buff = np.concatenate((x_buff, chunk), axis=0)\n",
    "            \n",
    "        index += imgCounter[i]\n",
    "#         print(index)\n",
    "    y_train = [i for i in range(1, 8) for j in range(n_samples)]\n",
    "    return x_buff, y_train\n",
    "\n",
    "if do_sampling:\n",
    "    x_train, y_train = sampling(x_train, 1500, ageRangeCounter)\n",
    "    \n",
    "print(len(x_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['models/svm_pca200_sfs70_20k.mat.pkl']"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm = SVC(verbose=True, C=1, tol=1e-4, )\n",
    "svm.fit(x_train, y_train)\n",
    "joblib.dump(svm, 'models/svm_{}.pkl'.format(featureMat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = joblib.load('models/svm_{}.pkl'.format(featureMat))\n",
    "svm.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['models/linearsvm_pca200_sfs70_20k.mat.pkl']"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linearsvm = LinearSVC(C=1, dual=False, verbose=True)\n",
    "linearsvm.fit(x_train, y_train)\n",
    "joblib.dump(linearsvm, 'models/linearsvm_{}.pkl'.format(featureMat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.32500000000000001"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linearsvm = joblib.load('models/linearsvm_{}.pkl'.format(featureMat))\n",
    "linearsvm.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['models/lda_pca200_sfs70_20k.mat.pkl']"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda = LinearDiscriminantAnalysis()\n",
    "lda.fit(x_train, y_train)\n",
    "joblib.dump(lda, 'models/lda_{}.pkl'.format(featureMat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.31785714285714284"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda = joblib.load('models/lda_{}.pkl'.format(featureMat))\n",
    "lda.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 2.04292366\n",
      "Iteration 2, loss = 1.66437152\n",
      "Iteration 3, loss = 1.37925131\n",
      "Iteration 4, loss = 1.16960556\n",
      "Iteration 5, loss = 1.05772447\n",
      "Iteration 6, loss = 0.99471169\n",
      "Iteration 7, loss = 0.95477586\n",
      "Iteration 8, loss = 0.92493180\n",
      "Iteration 9, loss = 0.90150246\n",
      "Iteration 10, loss = 0.88185792\n",
      "Iteration 11, loss = 0.86513983\n",
      "Iteration 12, loss = 0.85097337\n",
      "Iteration 13, loss = 0.83668688\n",
      "Iteration 14, loss = 0.82605136\n",
      "Iteration 15, loss = 0.81631131\n",
      "Iteration 16, loss = 0.80474637\n",
      "Iteration 17, loss = 0.79620061\n",
      "Iteration 18, loss = 0.78577586\n",
      "Iteration 19, loss = 0.77834267\n",
      "Iteration 20, loss = 0.76968943\n",
      "Iteration 21, loss = 0.76298387\n",
      "Iteration 22, loss = 0.75588787\n",
      "Iteration 23, loss = 0.74934411\n",
      "Iteration 24, loss = 0.74298041\n",
      "Iteration 25, loss = 0.73557676\n",
      "Iteration 26, loss = 0.73040725\n",
      "Iteration 27, loss = 0.72437337\n",
      "Iteration 28, loss = 0.71812799\n",
      "Iteration 29, loss = 0.71329762\n",
      "Iteration 30, loss = 0.70916916\n",
      "Iteration 31, loss = 0.70223304\n",
      "Iteration 32, loss = 0.69769694\n",
      "Iteration 33, loss = 0.69289557\n",
      "Iteration 34, loss = 0.68752252\n",
      "Iteration 35, loss = 0.68320030\n",
      "Iteration 36, loss = 0.67835937\n",
      "Iteration 37, loss = 0.67368460\n",
      "Iteration 38, loss = 0.66777771\n",
      "Iteration 39, loss = 0.66456834\n",
      "Iteration 40, loss = 0.65985128\n",
      "Iteration 41, loss = 0.65610309\n",
      "Iteration 42, loss = 0.65310282\n",
      "Iteration 43, loss = 0.64850281\n",
      "Iteration 44, loss = 0.64481021\n",
      "Iteration 45, loss = 0.64028552\n",
      "Iteration 46, loss = 0.63648802\n",
      "Iteration 47, loss = 0.63342626\n",
      "Iteration 48, loss = 0.62967706\n",
      "Iteration 49, loss = 0.62616821\n",
      "Iteration 50, loss = 0.62346338\n",
      "Iteration 51, loss = 0.62024904\n",
      "Iteration 52, loss = 0.61631494\n",
      "Iteration 53, loss = 0.61300477\n",
      "Iteration 54, loss = 0.61044731\n",
      "Iteration 55, loss = 0.60788508\n",
      "Iteration 56, loss = 0.60408026\n",
      "Iteration 57, loss = 0.60114772\n",
      "Iteration 58, loss = 0.59835755\n",
      "Iteration 59, loss = 0.59583164\n",
      "Iteration 60, loss = 0.59271662\n",
      "Iteration 61, loss = 0.59010551\n",
      "Iteration 62, loss = 0.58665091\n",
      "Iteration 63, loss = 0.58501564\n",
      "Iteration 64, loss = 0.58170930\n",
      "Iteration 65, loss = 0.57976675\n",
      "Iteration 66, loss = 0.57797486\n",
      "Iteration 67, loss = 0.57510097\n",
      "Iteration 68, loss = 0.57165201\n",
      "Iteration 69, loss = 0.56997357\n",
      "Iteration 70, loss = 0.56759695\n",
      "Iteration 71, loss = 0.56632803\n",
      "Iteration 72, loss = 0.56345035\n",
      "Iteration 73, loss = 0.56042897\n",
      "Iteration 74, loss = 0.55902193\n",
      "Iteration 75, loss = 0.55702386\n",
      "Iteration 76, loss = 0.55550146\n",
      "Iteration 77, loss = 0.55363208\n",
      "Iteration 78, loss = 0.55108551\n",
      "Iteration 79, loss = 0.55056228\n",
      "Iteration 80, loss = 0.54914550\n",
      "Iteration 81, loss = 0.54663116\n",
      "Iteration 82, loss = 0.54229041\n",
      "Iteration 83, loss = 0.54208783\n",
      "Iteration 84, loss = 0.54005904\n",
      "Iteration 85, loss = 0.53864295\n",
      "Iteration 86, loss = 0.53714124\n",
      "Iteration 87, loss = 0.53523001\n",
      "Iteration 88, loss = 0.53275080\n",
      "Iteration 89, loss = 0.53312251\n",
      "Iteration 90, loss = 0.52989006\n",
      "Iteration 91, loss = 0.52884816\n",
      "Iteration 92, loss = 0.52729758\n",
      "Iteration 93, loss = 0.52606654\n",
      "Iteration 94, loss = 0.52454409\n",
      "Iteration 95, loss = 0.52352498\n",
      "Iteration 96, loss = 0.52169755\n",
      "Iteration 97, loss = 0.51960778\n",
      "Iteration 98, loss = 0.51839301\n",
      "Iteration 99, loss = 0.51816804\n",
      "Iteration 100, loss = 0.51798055\n",
      "Iteration 101, loss = 0.51511183\n",
      "Iteration 102, loss = 0.51408828\n",
      "Iteration 103, loss = 0.51201908\n",
      "Iteration 104, loss = 0.51067790\n",
      "Iteration 105, loss = 0.51078651\n",
      "Iteration 106, loss = 0.50782293\n",
      "Iteration 107, loss = 0.50863054\n",
      "Iteration 108, loss = 0.50726411\n",
      "Iteration 109, loss = 0.50623546\n",
      "Iteration 110, loss = 0.50494909\n",
      "Iteration 111, loss = 0.50470029\n",
      "Iteration 112, loss = 0.50229854\n",
      "Iteration 113, loss = 0.49877629\n",
      "Iteration 114, loss = 0.49943386\n",
      "Iteration 115, loss = 0.49936349\n",
      "Iteration 116, loss = 0.49716184\n",
      "Iteration 117, loss = 0.49538566\n",
      "Iteration 118, loss = 0.49521347\n",
      "Iteration 119, loss = 0.49589829\n",
      "Iteration 120, loss = 0.49333288\n",
      "Iteration 121, loss = 0.49241533\n",
      "Iteration 122, loss = 0.49137672\n",
      "Iteration 123, loss = 0.48998580\n",
      "Iteration 124, loss = 0.48958090\n",
      "Iteration 125, loss = 0.48790980\n",
      "Iteration 126, loss = 0.48835747\n",
      "Iteration 127, loss = 0.48444464\n",
      "Iteration 128, loss = 0.48482560\n",
      "Iteration 129, loss = 0.48330091\n",
      "Iteration 130, loss = 0.48128626\n",
      "Iteration 131, loss = 0.48150086\n",
      "Iteration 132, loss = 0.48003503\n",
      "Iteration 133, loss = 0.47868373\n",
      "Iteration 134, loss = 0.47873468\n",
      "Iteration 135, loss = 0.48009636\n",
      "Iteration 136, loss = 0.47592802\n",
      "Iteration 137, loss = 0.47518449\n",
      "Iteration 138, loss = 0.47444834\n",
      "Iteration 139, loss = 0.47371779\n",
      "Iteration 140, loss = 0.47424107\n",
      "Iteration 141, loss = 0.47384525\n",
      "Iteration 142, loss = 0.46946372\n",
      "Iteration 143, loss = 0.46971116\n",
      "Iteration 144, loss = 0.46902660\n",
      "Iteration 145, loss = 0.46938924\n",
      "Iteration 146, loss = 0.46702725\n",
      "Iteration 147, loss = 0.46678417\n",
      "Iteration 148, loss = 0.46628275\n",
      "Iteration 149, loss = 0.46556303\n",
      "Iteration 150, loss = 0.46633429\n",
      "Iteration 151, loss = 0.46393512\n",
      "Iteration 152, loss = 0.46184120\n",
      "Iteration 153, loss = 0.46231384\n",
      "Iteration 154, loss = 0.46349075\n",
      "Iteration 155, loss = 0.46194824\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['models/nn_pca200_sfs100.mat.pkl']"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn = MLPClassifier(hidden_layer_sizes=(55, 25, 10), activation='relu', \n",
    "                   solver='adam', batch_size=512, verbose=True, max_iter=1000, tol=1e-4)\n",
    "nn.fit(x_train, y_train)\n",
    "joblib.dump(nn, 'models/nn_{}.pkl'.format(featureMat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.36071428571428571"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn = joblib.load('models/nn_{}.pkl'.format(featureMat))\n",
    "nn.score(x_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8\n",
      "242\n"
     ]
    }
   ],
   "source": [
    "def one_off_prediction(x_test, y_test, model):\n",
    "    oneOff = 0\n",
    "    for index, item in enumerate(x_test):\n",
    "        prediction = model.predict([x_test[index]])\n",
    "        if abs(prediction[0] - int(y_test[index])) <= 1:\n",
    "            oneOff += 1\n",
    "    \n",
    "    return oneOff/len(y_test)\n",
    "\n",
    "def total_error(x_test, y_test, model):\n",
    "    error = 0\n",
    "    for index, item in enumerate(x_test):\n",
    "        prediction = model.predict([x_test[index]])\n",
    "        error += abs(prediction[0] - int(y_test[index]))\n",
    "    return error\n",
    "\n",
    "print(one_off_prediction(x_test, y_test, nn))\n",
    "print(total_error(x_test, y_test, nn))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
